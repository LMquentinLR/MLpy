{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML.py, MLpy, MLPy!\n",
    "<p style=\"text-align: center;\">MLpy came as a simple question <i>and</i> a big project in pespective:\n",
    "<br><b>\"Can I build a discord bot that can tell two pictures apart?\"</b></p>\n",
    "<br>The goal of this notebook is two-fold with one overarching thread:\n",
    "\n",
    "1. To build a web crawler that can lift a statistically relevant number of images from [derpibooru](https://derpibooru.org), an image database powered by the community that built around the fourth generation of the show 'My Little Pony.'\n",
    "2. To build a machine learning algorithm capable of telling the difference between 2 types of pictures--to be summarized in a function that I can feed to my existing discord bot [BotJack](https://github.com/LMquentinLR/botjack_discord_bot).\n",
    "\n",
    "The thread is that I am, at the time of writing, learning how to program. I neither know how to build a web crawler or how a ML algorithm works (is it even called an algorithm?). All in all, this is a small idea that is both a learning experience, a blog--and of course a fun project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why a bot should do that?\n",
    "There are many reasons why a bot should be able to identify images posted on a server: classification, tagging, games, etc. \n",
    "<p style=\"text-align: center;\"><br>This notebook will focus on <b>compliance</b>.</p> \n",
    "\n",
    "* Servers may have anti-NSFW (i.e. not safe for watch) rules where explicit, grim, and otherwise unwanted content is banned or curtailed to specific server channels.\n",
    "* Moderation being volunteer-driven on discord, malicious users may capitalize on idle, asleep, or away-from-keyboard moderators to engage in rule-breaking activities. More commonly, users may simply post a NSFW picture in a SFW-only channel. \n",
    "* A bot able to distinguish NSFW content from SFW helps fill in the breaches that may affect any moderation effort. A bot, for instance, could automatically alert moderators when a specific content is posted and start a moderating process prior to any human intervention.\n",
    "\n",
    "<b>Automatic content moderation and compliance is a current industry effort in social media (e.g. Facebook)</b>, making this notebook a real world application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "import time\n",
    "import operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a web crawler\n",
    "Derpibooru is a website dedicated to fanart of MLP:FiM. It provides a JSON REST API for major site functionality, which can be freely used by anyone wanting to produce tools for the site or other webapps that use the data provided within Derpibooru.\n",
    "<br><b>Derpibooru licensing rules</b>\n",
    "<br>\"<i>Anyone can use it, users making abusively high numbers of requests may be asked to stop. Your application MUST properly cache, respect server-side cache expiry times. Your client MUST gracefully back off if requests fail (eg non-200 HTTP code), preferably exponentially or fatally.</i>\"\n",
    "\n",
    "<br>A single image can be accessed through the following links:\n",
    "1. https://derpibooru.org/2072316 (embedded)\n",
    "2. https://derpicdn.net/img/view/2019/6/22/2072316.png (default size)\n",
    "3. https://derpicdn.net/img/view/2019/6/22/2072316_small.png (small size)\n",
    "4. https://derpicdn.net/img/view/2019/6/22/2072316_medium.png (medium size)\n",
    "5. https://derpicdn.net/img/view/2019/6/22/2072316_large.png (large size)\n",
    "\n",
    "The metadata of a single picture can be accessed through the following link:\n",
    "* https://derpibooru.org/2072316.json\n",
    "<br> The list of attributes a single image is:\n",
    ">id, created_at, updated_at, first_seen_at, score, comment_count, width, height, file_name, description, uploader, uploader_id, image, upvotes, downvotes, faves, tags, tag_ids, aspect_ratio, original_format, mime_type, sha512_hash, orig_sha512_hash, source_url, representations, is_rendered, is_optimized, interactions, spoilered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class img_metadata:\n",
    "    \"\"\"\n",
    "    Class object that corresponds to the process retrieving picture metadata from the REST API\n",
    "    of the website derpibooru--data is retrieved as a series of est. 1Mb JSON files.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, tags = \"\", at_least_one = True, instances = 10):\n",
    "        \"\"\"\n",
    "        Initializes of the img_metadata class object.\n",
    "        ---\n",
    "        :param <self>:         <class>   ; class object reference\n",
    "        :param <tags>:         <list>    ; list of strings (i.e. picture tags)\n",
    "        :param <at_least_one>: <boolean> ; toggles between contains 'at least one tag' and 'all tags' in <tags>\n",
    "        :param <instances>:    <integer> ; number of instances/loops allowed before program stops\n",
    "        \"\"\"\n",
    "        self.tags = tags\n",
    "        self.at_least_one = at_least_one\n",
    "        self.instances = instances\n",
    "    \n",
    "    def convert_bytes(self, bytes_size):\n",
    "        \"\"\"\n",
    "        Converts byte lengths.\n",
    "        ---\n",
    "        :param <self>:       <class>   ; class object reference\n",
    "        :param <bytes_size>: <integer> ; size in bytes of a file\n",
    "        \"\"\"\n",
    "        for unit_multiple in ['bytes', 'KB', 'MB', 'GB', 'TB']:\n",
    "            if bytes_size < 1024.0:\n",
    "                return \"%3.1f %s\" % (bytes_size, unit_multiple)\n",
    "            bytes_size /= 1024.0\n",
    "    \n",
    "    def keys_to_keep(self):\n",
    "        \"\"\"\n",
    "        Returns the keys to keep in the JSON extract.\n",
    "        ---\n",
    "        :param <self>: <class> ; class object reference\n",
    "        \"\"\"\n",
    "        keys = [\"id\", \"created_at\", \"updated_at\", \"score\", \"uploader\",\n",
    "                \"uploader_id\", \"upvotes\", \"downvotes\", \"faves\", \"tags\",\n",
    "                \"tags_id\", \"representations\"]\n",
    "        return keys\n",
    "    \n",
    "    def json_split(self, path):\n",
    "        \"\"\"\n",
    "        Splits a json file if it is too large (1Mb).\n",
    "        ---\n",
    "        :param <self>: <class>  ; class object reference\n",
    "        :param <path>: <string> ; path of a json file\n",
    "        \"\"\"\n",
    "        length = self.convert_bytes(float(os.stat(path).st_size))\n",
    "        length = length.split(\" \")\n",
    "        if float(length[0]) >= 1.0 and length[1] == \"MB\":\n",
    "            nb_file = 0\n",
    "            while True:\n",
    "                new_path = path[:-5] + \"_\" + str(nb_file) + \".json\"\n",
    "                if os.path.exists(new_path) == False:\n",
    "                    print(\"SPLIT: JSON file to be split as 1Mb max size reached.\")\n",
    "                    os.rename(path, new_path) \n",
    "                    break\n",
    "                nb_file += 1\n",
    "    \n",
    "    def check_prior_extract(self, print_msg = True):\n",
    "        \"\"\"\n",
    "        Checks existing metadata extractions in the working directory. \n",
    "        The default file name is 'derpibooru_metadata.json'.\n",
    "        ---\n",
    "        :param <self>:      <class>   ; class object reference\n",
    "        :param <print_msg>: <boolean> ; toggle between 'prints message to command line' and 'prints nothing'\n",
    "        \"\"\"\n",
    "        \n",
    "        json_found = \"FOUND: 'derpibooru_metadata.json'\"\n",
    "        json_not_found = f\"MISSING FILE: 'derpibooru_metadata.json'; NOT IN: {os.getcwd()}\\n\" + \\\n",
    "        \"FILE TO CREATE: 'derpibooru_metadata.json'\"\n",
    "        json_created = \"FILE CREATED: 'derpibooru_metadata.json'\"\n",
    "        json_not_created = \"ERROR FILE CREATION: 'derpibooru_metadata.json'\"\n",
    "        json_path = os.getcwd() + \"\\\\derpibooru_metadata.json\"\n",
    "        \n",
    "        find = os.path.exists(json_path)\n",
    "        \n",
    "        #if TRUE: opens file and extracts the contained metadata\n",
    "        #if FALSE: creates file storing an empty list\n",
    "        if find:\n",
    "            if print_msg: print(json_found)\n",
    "        else:\n",
    "            if print_msg: print(json_not_found)\n",
    "            try:    \n",
    "                with open(json_path, \"w\") as file: file.write(\"[]\")   \n",
    "                print(json_created) \n",
    "            except Exception as e: print(json_not_created, e, sep = \"\\n\")\n",
    "        \n",
    "        return json_path\n",
    "\n",
    "    def json_collect(self, json_local, json_derpibooru, json_path):\n",
    "        \"\"\"\n",
    "        Collects picture metadata extracted from derpibooru.\n",
    "        ---\n",
    "        :param <self>:            <class>       ; class object reference\n",
    "        :param <json_local>:      <json_object> ; JSON data stored locally\n",
    "        :param <json_derpibooru>: <json_object> ; JSON data extracted from derpibooru\n",
    "        :param <json_path>:       <string>      ; path of local file where the data is stored\n",
    "        \"\"\"\n",
    "        stored_keys = self.keys_to_keep()\n",
    "        last_id = -1\n",
    "        \n",
    "        for image_data in json_derpibooru:\n",
    "            \n",
    "            temp = image_data.copy()\n",
    "            \n",
    "            for item in image_data: \n",
    "                if item not in stored_keys: del temp[item]\n",
    "            \n",
    "            last_id = max(image_data[\"id\"], last_id)\n",
    "            \n",
    "            json_local.append(temp)\n",
    "            json_local.sort(key=operator.itemgetter(\"id\"), reverse = True)\n",
    "\n",
    "        with open(json_path,'w') as file: json.dump(json_local, file)\n",
    "        \n",
    "        self.json_split(json_path)\n",
    "        \n",
    "        return last_id\n",
    "\n",
    "    def crawl_metadata(self):\n",
    "        \"\"\"\n",
    "        Retrieves from the derpibooru REST API a list of picture metadata.\n",
    "        ---\n",
    "        :param <self>: <class> ; class object reference\n",
    "        \"\"\"\n",
    "        #initializes local variables    \n",
    "        iterations = self.instances\n",
    "        back_off_counter = 1\n",
    "        max_instances_reached = \"The set maximum number of images to request was reached \" + \\\n",
    "                                f\"at {self.instances}.\"\n",
    "        exit_condition = \"The crawler scraped the derpibooru metadata. The program will \" + \\\n",
    "                         \"now close.\"\n",
    "        \n",
    "        #retrieves most recent recorded picture id\n",
    "        if os.path.exists(\"derpibooru_metadata.json\"): json_path = \"derpibooru_metadata.json\"\n",
    "        else: json_path = self.check_prior_extract()\n",
    "        \n",
    "        with open(json_path, \"r\") as file: requested_id = json.load(file)\n",
    "        \n",
    "        if requested_id == []: requested_id = 1\n",
    "        else: requested_id = requested_id[0][\"id\"] + 1\n",
    "        \n",
    "        while True:\n",
    "            requested_page = \"You are requesting the derpibooru page starting with the \" + \\\n",
    "                             f\"id {requested_id}.\"\n",
    "            error_json_extraction = \"The program couldn't extract the page and \" + \\\n",
    "                                    \"will now proceed to an exponential back off.\"\n",
    "            \n",
    "            #checks if previous JSON was not renamed due to the 1Mb splitting\n",
    "            json_path = self.check_prior_extract(False)\n",
    "            \n",
    "            with open(json_path,'r') as file: json_local = json.load(file)\n",
    "            \n",
    "            print(requested_page)\n",
    "            \n",
    "            path_derpibooru = \"https://derpibooru.org/images.json?constraint=id&order=a&gt=\" + \\\n",
    "                              str(requested_id)\n",
    "            \n",
    "            try:\n",
    "                if type(iterations) == int:\n",
    "                    if iterations > 1: iterations -= 1\n",
    "                    else: break\n",
    "                \n",
    "                json_derpibooru = requests.get(path_derpibooru).json()[\"images\"]\n",
    "                if json_derpibooru == []: raise DatabaseFullyCrawled\n",
    "                \n",
    "                requested_id = self.json_collect(json_local, json_derpibooru, json_path)\n",
    "                \n",
    "                #time delay to respect the API's license\n",
    "                time.sleep(.250)\n",
    "            \n",
    "            except DatabaseFullyCrawled:\n",
    "                print(exit_condition)\n",
    "                break\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                print(error_json_extraction)\n",
    "                print(f\"The error was the following: {e}.\\n The program will back \" + \\\n",
    "                      f\"off for {2**back_off_counter} seconds.\")\n",
    "                back_off_counter += 1\n",
    "                time.sleep(2 ** back_off_counter)\n",
    "    \n",
    "    def id_filter(self, tags, at_least_one):\n",
    "        \"\"\"\n",
    "        Retrieves the IDs of the locally stored metadata that fit specific tag parameters\n",
    "        ---\n",
    "        :param <self>:         <class>   ; class object reference\n",
    "        :param <tags>:         <list>    ; list of strings (i.e. picture tags)\n",
    "        :param <at_least_one>: <boolean> ; toggles between contains 'at least one tag' and 'all tags' in <tags>\n",
    "        \"\"\"\n",
    "        def any_or_all(boolean):\n",
    "            \"\"\"\n",
    "            Returns the function any() if argument <boolean> TRUE, else returns function all()\n",
    "            ---\n",
    "            :param <boolean>: <boolean> ; boolean value\n",
    "            \"\"\"\n",
    "            if boolean == True:\n",
    "                return any\n",
    "            else:\n",
    "                return all\n",
    "        \n",
    "        metadata_files_list = filter(lambda file: file.startswith(\"derpibooru_metadata\"), \n",
    "                                     os.listdir(os.getcwd()))\n",
    "        metadata_files_list = list(metadata_files_list)\n",
    "        \n",
    "        id_list = []\n",
    "        url_list = []\n",
    "        \n",
    "        for fname in metadata_files_list:\n",
    "            \n",
    "            with open(fname,\"r\") as file: json_local = json.load(file)\n",
    "            if json_local == []: break\n",
    "            \n",
    "            tags_keep = list(filter(lambda item: item.startswith(\"+\"), tags))\n",
    "            tags_keep = list(map(lambda item: item[1:], tags_keep))\n",
    "            tags_remove = list(filter(lambda item: item.startswith(\"-\"), tags))\n",
    "            tags_remove = list(map(lambda item: item[1:], tags_remove))\n",
    "            \n",
    "            fltr = any_or_all(at_least_one)\n",
    "            filter_keep = lambda item: fltr(tag in item[\"tags\"].split(\", \") for tag in tags_keep)\n",
    "            filter_remove = lambda item: not any(tag in item[\"tags\"].split(\", \") for tag in tags_remove)\n",
    "            json_kept = list(filter(filter_keep, json_local))\n",
    "            json_kept = list(filter(filter_remove, json_kept))\n",
    "            \n",
    "            filter_id = lambda item: item[\"id\"]\n",
    "            filter_url = lambda item: item[\"representations\"][\"tall\"][2:]\n",
    "            id_list += list(map(filter_id, json_kept))\n",
    "            url_list += list(map(filter_url, json_kept))\n",
    "            \n",
    "        return list(zip(id_list, url_list))\n",
    "    \n",
    "    def repair_tags(self):\n",
    "        \"\"\"\n",
    "        Checks if all retrieved IDs have an available list of tags.\n",
    "        ---\n",
    "        :param <self>:         <class>    ; class object reference\n",
    "        \"\"\"\n",
    "        metadata_files_list = filter(lambda file: file.startswith(\"derpibooru_metadata\"), \n",
    "                                     os.listdir(os.getcwd()))\n",
    "        metadata_files_list = list(metadata_files_list)\n",
    "        \n",
    "        for fname in metadata_files_list:\n",
    "            \n",
    "            with open(fname, \"r\") as file: \n",
    "                \n",
    "                json_local = json.load(file)\n",
    "                if json_local == []:break\n",
    "                \n",
    "                for index, item in enumerate(json_local):\n",
    "\n",
    "                    if item[\"tags\"] == None:\n",
    "                        json_id = item[\"id\"]\n",
    "                        path_derpibooru = \"https://derpibooru.org/\" + str(json_id) + \".json\"\n",
    "\n",
    "                        try:\n",
    "                            json_derpibooru = requests.get(path_derpibooru).json()\n",
    "                            time.sleep(.250)\n",
    "                            if json_derpibooru[\"tags\"] == None: raise AbsentTagList\n",
    "                            json_local[index][\"tags\"] = json_derpibooru[\"tags\"]\n",
    "                            print(f\"The tags of the picture {json_id} were updated.\")\n",
    "\n",
    "                        except AbsentTagList:\n",
    "                            print(f\"The url request for the picture {json_id} returned an empty list of tags.\")\n",
    "\n",
    "                        except Exception as e:\n",
    "                            print(e)\n",
    "                \n",
    "            with open(fname,'w') as file: json.dump(json_local, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class derpibooru_search(img_metadata):\n",
    "    \"\"\"\n",
    "    Class object that corresponds to a search prompting the derpibooru REST API and\n",
    "    retrieve both picture metadata and the affiliated pictures.\n",
    "    \"\"\"\n",
    "    \n",
    "    def change_search(self, tags = \"\", at_least_one = True, instances = 50):\n",
    "        \"\"\"\n",
    "        Changes the arguments of the created object derpibooru_search.\n",
    "        ---\n",
    "        :param <self>:         <class>    ; class object reference\n",
    "        :param <tags>:         <list>     ; list of strings (i.e. picture tags) used for sorting\n",
    "        :param <tags>:         <list>    ; list of strings (i.e. picture tags)\n",
    "        :param <at_least_one>: <boolean> ; toggles between contains 'at least one tag' and 'all tags' in <tags>\n",
    "        \"\"\"\n",
    "        self.tags = tags\n",
    "        self.at_least_one = at_least_one\n",
    "        self.instances = instances\n",
    "\n",
    "    def crawl(self):\n",
    "        \"\"\"\n",
    "        Changes the arguments of the created object derpibooru_search.\n",
    "        ---\n",
    "        :param <self>: <class> ; class object reference\n",
    "        \"\"\"\n",
    "        print(\"----|Entering Derpibooru Data Crawler code|----\")\n",
    "        self.crawl_metadata()\n",
    "        print(\"---------------|Exiting Program|---------------\")\n",
    "    \n",
    "    def retrieve_ids(self):\n",
    "        \"\"\"\n",
    "        Retrieves the IDs of the locally stored metadata that fit specific tag parameters.\n",
    "        ---\n",
    "        :param <self>: <class> ; class object reference\n",
    "        \"\"\"\n",
    "        print(\"----|Retrieving IDs based on tag selection|----\")\n",
    "        id_list = self.id_filter(self.tags, self.at_least_one)\n",
    "        print(\"----------------|IDs retrieved|----------------\")\n",
    "        return id_list\n",
    "    \n",
    "    def repair(self):\n",
    "        \"\"\"\n",
    "        Repairs missing tags of the locally stored metadata .\n",
    "        ---\n",
    "        :param <self>: <class> ; class object reference\n",
    "        \"\"\"\n",
    "        print(\"----|Repairing missing tags in stored JSON|----\")\n",
    "        self.repair_tags()\n",
    "        print(\"----------------|Tags repaired|----------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Error(Exception):\n",
    "    \"\"\"Base class for other exceptions\"\"\"\n",
    "    pass\n",
    "\n",
    "class DatabaseFullyCrawled(Error):\n",
    "    \"\"\"Raised when the crawler reached the last pages of derpibooru\"\"\"\n",
    "    pass\n",
    "\n",
    "class NewContentCrawled(Error):\n",
    "    \"\"\"Raised when the input value is too large\"\"\"\n",
    "    pass\n",
    "\n",
    "class AbsentTagList(Error):\n",
    "    \"\"\"Raised when the key value of the key 'tags' in a dictionary is 'None'\"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = derpibooru_search()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crawling Tests\n",
    "1. Test #1 would retrieve all existing available picture metadata but will stop at the 10th requested page\n",
    "2. Test #2 will retrieve all existing available picture metadata (can take up to 60h as at July 2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj.__dict__\n",
    "obj.change_search(instances = 10)\n",
    "obj.crawl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "obj.__dict__\n",
    "obj.change_search(instances = \"\")\n",
    "obj.crawl()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes, retrieved metadata would be missing their tags. The following repairs them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj.repair()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving IDs based on tag selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This version of the search function takes a list of strings which must match the following format:\n",
    "<br><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\"+tag\" <i>or</i> \"-tag\"\n",
    "<br><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<b>+</b> indicates keeping the ID for search, <b>-</b> indicates removing the ID for search.\n",
    "<br><br>The [at_least_one] variable indicates:\n",
    "1. if TRUE: the retrieved IDs will <b>only</b> be the ones which tags <b>contain at least one</b> of the items listed in the variable [tags] with a \"+\" prefix\n",
    "2. if FALSE: the retrieved IDs will <b>only</b> be the ones which tags <b>contain all</b> of the items listed in the variable [tags]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_tags = [\"+rarity\",\"+applejack\",\"+ship\", \"-animated\"]\n",
    "search_include = False\n",
    "obj.change_search(tags = search_tags, at_least_one = search_include)\n",
    "id_list = obj.retrieve_ids()\n",
    "\n",
    "print(len(id_list))\n",
    "print(id_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving pictures based on retrieved IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
